{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "# Iterative methods\n",
    "\n",
    "The methods we discussed in earlier sections, e.g., Gauss(-Jordan) eliminations and LU decompositions, are all direct methods, in which we compute the solution with a finite number of operations. In this section, we will introduce a different class of methods, the **iterative methods**, or **indirect methods**. It starts with an initial guess of the solution and then repeatedly improve the solution until the change of the solution is below a threshold. In order to use this iterative process, we need first write the explicit form of a system of equations. \n",
    "\n",
    "If we have a system of linear equations:\n",
    "\n",
    "$$\\begin{bmatrix}\n",
    "a_{1,1} & a_{1,2} & ... & a_{1,n}\\\\\n",
    "a_{2,1} & a_{2,2} & ... & a_{2,n}\\\\\n",
    "... & ... & ... & ... \\\\\n",
    "a_{m,1} & a_{m,2} & ... & a_{m,n}\n",
    "\\end{bmatrix}\\left[\\begin{array}{c} x_1 \\\\x_2 \\\\ ... \\\\x_n \\end{array}\\right] =\n",
    "\\left[\\begin{array}{c} y_1 \\\\y_2 \\\\ ... \\\\y_m \\end{array}\\right]$$\n",
    "we can write its explicit form as:\n",
    "\n",
    "$$\n",
    "x_i = \\frac{1}{a_{i,i}}\\Big[y_i - \\sum_{j=1, j \\ne i}^{j=n}{a_{i,j}x_j} \\Big]\n",
    "$$\n",
    "\n",
    "This is the basics of the iterative methods, we can assume initial values for all the $x$, and use it as $x^{(0)}$. In the first iteration, we can substitute $x^{(0)}$ into the right-hand side of the explicit equation above, and get the first iteration solution $x^{(1)}$. Thus, we can substitute $x^{(1)}$ into the equation and get substitute $x^{(2)}$. The iterations continue until the difference between $x^{(k)}$ and $x^{(k-1)}$ is smaller than some pre-defined value. \n",
    "\n",
    "In order to have the iterative methods work, we do need specific condition for the solution to converge. A sufficient but not necessary condition of the convergence is the coefficient matrix $a$ is a **diagonally dominant**. This means that in each row of the matrix of coefficients $a$, the absolute value of the diagonal element is greater than the sum of the absolute values of the off-diagonal elements. If the coefficient matrix satisfy the condition, the iteration will converge to the solution. The solution might still converge even when this condition is not satisfied.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gauss-Seidel Method\n",
    "\n",
    "The **Gauss-Seidel Method** is a specific iterative method, that is always using the latest estimated value for each elements in $x$. For example, we first assume the initial values for $x_2, x_3, \\cdots, x_n$ (except for $x_1$), and then we can calculate $x_1$. Using the calculated $x_1$ and the rest of the $x$ (except for $x_2$), we can calculate $x_2$. We can continue in the same manner and calculate all the elements in $x$. This will conclude the first iteration. We can see the unique part of Gauss-Seidel method is that we are always using the latest value for calculate the next value in $x$. We can then continue with the iterations until the value converges. \n",
    "\n",
    "**EXAMPLE:** Solve the following system of linear equations using Gauss-Seidel method, use a pre-defined threshold $\\epsilon = 1\\textrm{e-6} = 10^{-6}$. Do remember to check if the converge condition is satisfied or not. \n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "8x_1 + 3x_2 - 3x_3 &= 14 \\\\\n",
    "-2x_1 - 8x_2 + 5x_3 &= 5 \\\\\n",
    "3x_1 + 5x_2 + 10x_3 &= -8\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "Let us first check if the coefficient matrix is diagonally dominant or not. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matrix is diagonally dominant\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "a = [[8, 3, -3], [-2, -8, 5], [3, 5, 10]]\n",
    "\n",
    "# Find diagonal coefficients\n",
    "diag = np.diag(np.abs(a)) \n",
    "\n",
    "# Find row sum without diagonal\n",
    "off_diag = np.sum(np.abs(a), axis=1) - diag \n",
    "\n",
    "if np.all(diag > off_diag):\n",
    "    print('matrix is diagonally dominant')\n",
    "else:\n",
    "    print('NOT diagonally dominant')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since it is guaranteed to converge, we can use Gauss-Seidel method to solve it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration results\n",
      " k,    x1,    x2,    x3 \n",
      "1, 1.7500, -1.0625, -0.7937\n",
      "2, 1.8508, -1.5838, -0.5633\n",
      "3, 2.1327, -1.5103, -0.6847\n",
      "4, 2.0596, -1.5678, -0.6340\n",
      "5, 2.1002, -1.5463, -0.6569\n",
      "6, 2.0835, -1.5565, -0.6468\n",
      "7, 2.0911, -1.5520, -0.6513\n",
      "8, 2.0878, -1.5540, -0.6493\n",
      "9, 2.0893, -1.5531, -0.6502\n",
      "10, 2.0886, -1.5535, -0.6498\n",
      "11, 2.0889, -1.5534, -0.6500\n",
      "12, 2.0888, -1.5534, -0.6499\n",
      "13, 2.0888, -1.5534, -0.6499\n",
      "Converged!\n",
      "x1 =  2.088820613469093\n",
      "x2 =  -1.5534002543643612\n",
      "x3 =  -0.6499460568585473\n",
      "Sanity check:\n",
      "y1 = 8*x1 + 3*x2 - 3*x3 = 14.000202315235303\n",
      "y2 = -2*x1 - 8*x2 + 5*x3= 4.999830523683967\n",
      "y3 = 3*x1 + 5*x2 + 10*x3= -8.0\n"
     ]
    }
   ],
   "source": [
    "x1 = 0\n",
    "x2 = 0\n",
    "x3 = 0\n",
    "epsilon = 0.0001\n",
    "converged = False\n",
    "\n",
    "x_old = np.array([x1, x2, x3])\n",
    "\n",
    "print('Iteration results')\n",
    "print(' k,    x1,    x2,    x3 ')\n",
    "for k in range(1, 50):\n",
    "    x1 = (14-3*x2+3*x3)/8\n",
    "    x2 = (5+2*x1-5*x3)/(-8)\n",
    "    x3 = (-8-3*x1-5*x2)/(10)\n",
    "    x = np.array([x1, x2, x3])\n",
    "    # check if it is smaller than threshold\n",
    "    dx = np.sqrt(np.dot(x-x_old, x-x_old))\n",
    "    \n",
    "    print(\"%d, %.4f, %.4f, %.4f\"%(k, x1, x2, x3))\n",
    "    if dx < epsilon:\n",
    "        converged = True\n",
    "        print('Converged!')\n",
    "        print('x1 = ', x1)\n",
    "        print('x2 = ', x2)\n",
    "        print('x3 = ', x3)\n",
    "        break\n",
    "        \n",
    "    # assign the latest x value to the old value\n",
    "    x_old = x\n",
    "\n",
    "if not converged:\n",
    "    print('Not converged, increase the # of iterations')\n",
    "    \n",
    "print('Sanity check:')\n",
    "\n",
    "y1 = 8*x1 + 3*x2 - 3*x3\n",
    "y2 = -2*x1 - 8*x2 + 5*x3\n",
    "y3 = 3*x1 + 5*x2 + 10*x3\n",
    "\n",
    "print('y1 = 8*x1 + 3*x2 - 3*x3 =', y1)\n",
    "print('y2 = -2*x1 - 8*x2 + 5*x3=', y2)\n",
    "print('y3 = 3*x1 + 5*x2 + 10*x3=', y3)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
